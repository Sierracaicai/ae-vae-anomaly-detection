# ðŸ” AE-VAE Anomaly Detection

This project evaluates and compares anomaly detection approaches on network traffic data using:

- ðŸ§  Deep learning methods: Autoencoder (AE), Variational Autoencoder (VAE)
- ðŸ§ª Classical methods: Isolation Forest, One-Class SVM

> Built as a portfolio-grade, modular and reproducible data science project.

---

## ðŸ“ Project Structure

```
ae-vae-anomaly-detection/
â”œâ”€â”€ notebooks/                 # Step-by-step notebooks for exploration and training
â”‚   â””â”€â”€ 0_exploration_and_baseline.ipynb
â”œâ”€â”€ src/                       # Source code modules
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ eda_tools.py       # Reusable EDA functions
â”‚   â”‚   â”œâ”€â”€ preprocess.py      # Data cleaning, transformation, encoding, scaling
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ models/                # (Planned) AE/VAE architectures and trainers
â”œâ”€â”€ data/                      # Raw and processed data
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”œâ”€â”€ docs/                      # Module-level documentation (EDA, Preprocessing, Experiments)
â”‚   â””â”€â”€ feature_review.md
â”œâ”€â”€ README.md
```

---

## ðŸ“Š Dataset

**UNSW-NB15** â€” A modern labeled network intrusion detection dataset.

- 49 features + `attack_cat` + binary `label`
- Mixture of normal traffic and multiple attack types
- Used only the first 100,000 rows for initial development (scalable)

---

## ðŸ§° Core Modules

### ðŸ”¹ EDA Tools (`src/utils/eda_tools.py`)

Reusable, production-ready utilities for data inspection and visualization.

- Distribution histograms, label counts
- Outlier detection (Z-score)
- Correlation heatmaps
- Distribution drift analysis (KS-test)

ðŸ“˜ See [docs/EDA Tools](src/utils/eda_tools.md)

---

### ðŸ”¹ Data Preprocessing (`src/utils/preprocess.py`)

- Categorical encoding (one-hot)
- MinMax/Standard scaling
- Optional log1p transformation
- Auto correlation filtering
- Cleaned output saved to CSV

---

## ðŸ”¬ Models and Experiments

| Model            | Type         | Status  | Notes                                   |
|------------------|--------------|---------|-----------------------------------------|
| Autoencoder      | Deep Learning | âœ… Done | Shallow AE with Dropout + BN            |
| VAE              | Deep Learning | âœ… Done | Custom training loop + KL-div loss      |
| Isolation Forest | Traditional  | âœ… Done | Baseline comparison                      |
| One-Class SVM    | Traditional  | âœ… Done | Baseline comparison                      |

ðŸ“ˆ Metrics: MSE reconstruction error, AUC, precision, recall

---

## ðŸ§ª Experimental Design

- Trained AE/VAE on **normal samples only**
- Tested on **mixed samples (normal + anomalous)**
- Compared anomaly scores across methods
- Evaluated impact of:
  - Sample size
  - Thresholding method
  - Feature engineering
  - Model complexity

---

## ðŸ” Future Work

- Add interpretability via SHAP / LIME
- Hyperparameter tuning and AE/VAE deepening
- Build modular `train_runner.py`
- Add CLI + logging support for reproducible runs

---

## ðŸ‘©â€ðŸ’» Author

Created by [Your Name] Â· Portfolio Project  
> *Feel free to fork, study or reuse parts of this repo in your own data science learning path.*